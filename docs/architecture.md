# TruthLens AI - System Architecture

## ðŸ“ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Browser                          â”‚
â”‚                     (Frontend - HTML/JS)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/REST
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Backend                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   API       â”‚  â”‚   Auth       â”‚  â”‚   Logging    â”‚      â”‚
â”‚  â”‚  Endpoints  â”‚  â”‚  Middleware  â”‚  â”‚   System     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                â”‚                â”‚
           â–¼                â–¼                â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   ML Model     â”‚ â”‚  Database   â”‚ â”‚ Web Search   â”‚
  â”‚   (PyTorch)    â”‚ â”‚  (SQLite)   â”‚ â”‚  API Client  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                  â”‚
           â–¼                                  â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Transformers   â”‚                â”‚  SerpAPI/    â”‚
  â”‚  XLM-RoBERTa   â”‚                â”‚  Bing API    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ—ï¸ Component Architecture

### 1. Frontend Layer

**Technology**: HTML5, TailwindCSS, Vanilla JavaScript

**Components**:
```
frontend/
â”œâ”€â”€ index.html          # Main UI with all pages
â”œâ”€â”€ script.js          # JavaScript logic (embedded)
â””â”€â”€ style.css          # Custom styles (embedded)
```

**Responsibilities**:
- User interface rendering
- Input validation
- API communication
- Result visualization
- History management (localStorage)
- Dark/light mode
- Language switching

**Key Features**:
- Single Page Application (SPA) pattern
- Responsive design (mobile-first)
- Real-time feedback
- Loading states
- Error handling

---

### 2. Backend Layer

**Technology**: FastAPI, Python 3.9+, Uvicorn

**Structure**:
```
backend/
â”œâ”€â”€ app.py             # Main FastAPI application
â”œâ”€â”€ model.py           # ML inference engine
â”œâ”€â”€ search_api.py      # Web search integration
â”œâ”€â”€ database.py        # Data persistence
â””â”€â”€ utils.py           # Helper functions
```

**API Endpoints**:
```python
POST   /analyze        # Main analysis endpoint
GET    /health         # Health check
GET    /history        # User history
POST   /feedback       # Submit feedback
GET    /stats          # System statistics
GET    /docs           # API documentation
```

**Responsibilities**:
- Request routing
- Input validation (Pydantic)
- Business logic coordination
- Error handling
- Response formatting
- Logging

---

### 3. ML Model Layer

**Technology**: PyTorch, Transformers, Sentence-Transformers

**Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FakeNewsDetector               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Text Preprocessing                  â”‚
â”‚     - Cleaning                          â”‚
â”‚     - Normalization                     â”‚
â”‚     - Language detection                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. Tokenization                        â”‚
â”‚     - XLM-RoBERTa Tokenizer            â”‚
â”‚     - Max length: 512 tokens           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. Model Inference                     â”‚
â”‚     - Forward pass                      â”‚
â”‚     - Softmax activation               â”‚
â”‚     - Confidence calculation           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. Feature Extraction                  â”‚
â”‚     - Keyword extraction               â”‚
â”‚     - Attention weights                â”‚
â”‚     - Embedding generation             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  5. Post-processing                     â”‚
â”‚     - Label mapping                     â”‚
â”‚     - Explanation generation           â”‚
â”‚     - Result formatting                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Models Used**:
- **Classification**: `xlm-roberta-base` (500MB)
  - Input: Text (any language)
  - Output: Fake/Real + Confidence
  
- **Embeddings**: `sentence-transformers/all-MiniLM-L6-v2` (80MB)
  - Input: Text or query
  - Output: 384-dim vector
  - Use: Semantic similarity

**Inference Pipeline**:
```python
Input Text
    â†“
Language Detection (langdetect)
    â†“
Text Cleaning (regex, normalization)
    â†“
Tokenization (XLM-RoBERTa tokenizer)
    â†“
Model Forward Pass (PyTorch)
    â†“
Softmax & Confidence Calculation
    â†“
Keyword Extraction (TF-IDF)
    â†“
Result Assembly
    â†“
Output JSON
```

---

### 4. Search Integration Layer

**Technology**: REST API clients, BeautifulSoup

**Supported APIs**:
1. **SerpAPI** (Primary)
   - 100 free requests/month
   - Best quality results
   
2. **Bing Search API** (Secondary)
   - Microsoft Azure required
   - Good coverage
   
3. **Fallback** (Demo mode)
   - Mock results
   - No API key needed

**Search Pipeline**:
```
User Query
    â†“
Extract Keywords
    â†“
API Call (SerpAPI/Bing)
    â†“
Parse Results (title, URL, snippet)
    â†“
Semantic Similarity Scoring
    â†“
Rank by Relevance
    â†“
Filter by Trustworthiness
    â†“
Return Top 5 Sources
```

**Source Ranking Algorithm**:
```python
relevance_score = 
    0.6 * semantic_similarity +
    0.3 * source_trustworthiness +
    0.1 * freshness
```

---

### 5. Database Layer

**Technology**: SQLite (development), PostgreSQL-ready

**Schema**:
```sql
-- Users table
CREATE TABLE users (
    id INTEGER PRIMARY KEY,
    email TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Analyses table
CREATE TABLE analyses (
    id INTEGER PRIMARY KEY,
    user_id TEXT,
    text TEXT NOT NULL,
    text_hash TEXT NOT NULL,  -- For caching
    classification TEXT NOT NULL,
    confidence REAL NOT NULL,
    language TEXT NOT NULL,
    explanation TEXT,
    sources TEXT,  -- JSON
    keywords TEXT,  -- JSON
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Feedback table
CREATE TABLE feedback (
    id INTEGER PRIMARY KEY,
    analysis_id INTEGER NOT NULL,
    user_id TEXT,
    rating TEXT NOT NULL,  -- 'up' or 'down'
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (analysis_id) REFERENCES analyses(id)
);

-- Statistics table
CREATE TABLE statistics (
    id INTEGER PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    total_analyses INTEGER DEFAULT 0,
    fake_count INTEGER DEFAULT 0,
    real_count INTEGER DEFAULT 0,
    avg_confidence REAL DEFAULT 0,
    unique_users INTEGER DEFAULT 0
);
```

**Caching Strategy**:
- Cache key: MD5 hash of cleaned text
- TTL: 24 hours
- Hit rate target: >30%

---

## ðŸ”„ Data Flow

### Analysis Request Flow

```
1. User inputs text in Frontend
        â†“
2. Frontend validates (min 10 words)
        â†“
3. POST /analyze to Backend
        â†“
4. Backend preprocesses text
        â†“
5. Check cache (text_hash)
        â”œâ”€ Hit: Return cached result
        â””â”€ Miss: Continue â†“
6. Detect language (EN/RU/KZ)
        â†“
7. ML model prediction
        â†“
8. If confidence < 0.75 OR deep mode:
   â”œâ”€ Perform web search
   â”œâ”€ Rank sources by similarity
   â””â”€ Generate evidence
        â†“
9. Generate explanation
        â†“
10. Save to database
        â†“
11. Return JSON response
        â†“
12. Frontend displays results
```

### Request/Response Format

**Request**:
```json
POST /analyze
{
  "text": "News article text here...",
  "mode": "quick",
  "user_id": "user123"
}
```

**Response**:
```json
{
  "classification": "fake",
  "confidence": 0.87,
  "language": "en",
  "explanation": "This content contains unverified claims...",
  "sources": [
    {
      "title": "Reuters Fact Check",
      "url": "https://...",
      "snippet": "...",
      "relevance": 0.92
    }
  ],
  "keywords": ["unverified", "contradicts"],
  "timestamp": "2025-10-10T12:34:56Z"
}
```

---

## âš¡ Performance Optimizations

### 1. Model Loading
- **Lazy loading**: Models load on first request
- **Singleton pattern**: One model instance shared
- **Memory management**: Automatic garbage collection

### 2. Caching
- **Query cache**: MD5-based text hashing
- **Model cache**: Hugging Face local cache
- **API cache**: 24-hour TTL for search results

### 3. Concurrent Processing
- **Async/await**: FastAPI async endpoints
- **Background tasks**: Non-blocking DB writes
- **Connection pooling**: Database connections

### 4. Resource Management
- **GPU utilization**: Automatic CUDA detection
- **CPU fallback**: Works without GPU
- **Memory limits**: Max 4GB recommended

---

## ðŸ”’ Security Architecture

### Input Validation
- **Length limits**: 10-10,000 words
- **SQL injection**: Parametrized queries
- **XSS protection**: HTML escaping
- **CORS**: Configured origins only

### Authentication (Optional)
- **Password hashing**: bcrypt
- **Session management**: JWT tokens
- **Rate limiting**: 100 requests/hour/user

### Data Privacy
- **No PII collection**: Anonymous by default
- **Opt-in history**: User choice
- **Secure storage**: Encrypted at rest

---

## ðŸ“Š Monitoring & Logging

### Logging Strategy
```python
logs/
â”œâ”€â”€ app.log          # Application logs
â”œâ”€â”€ error.log        # Errors only
â””â”€â”€ access.log       # API access logs
```

### Log Levels
- **DEBUG**: Development details
- **INFO**: Normal operations
- **WARNING**: Unusual but handled
- **ERROR**: Errors that need attention
- **CRITICAL**: System failures

### Metrics Tracked
- Request count
- Response time (P50, P95, P99)
- Error rate
- Cache hit rate
- Model accuracy
- User engagement

---

## ðŸš€ Deployment Architecture

### Development
```
localhost:8000 (Backend)
localhost:8080 (Frontend)
SQLite database
Mock search results
```

### Production
```
render.com/huggingface.co (Backend)
CDN (Frontend static files)
PostgreSQL (Database)
Real API keys (Search)
```

### Scaling Strategy
- **Horizontal**: Multiple backend instances
- **Load balancer**: Nginx/AWS ALB
- **Cache layer**: Redis
- **CDN**: Static assets
- **Database**: Read replicas

---

## ðŸ”§ Technology Stack Summary

| Layer | Technology | Version |
|-------|-----------|---------|
| Frontend | HTML/CSS/JS | ES6+ |
| UI Framework | TailwindCSS | 3.x |
| Backend | FastAPI | 0.104+ |
| Server | Uvicorn | 0.24+ |
| ML Framework | PyTorch | 2.1+ |
| NLP | Transformers | 4.35+ |
| Embeddings | Sentence-Transformers | 2.2+ |
| Database | SQLite/PostgreSQL | - |
| Language Detection | langdetect | 1.0+ |
| Web Client | requests | 2.31+ |

---

## ðŸ“ˆ Future Architecture Enhancements

### Phase 2
- Microservices architecture
- Message queue (RabbitMQ)
- Caching layer (Redis)
- Monitoring (Prometheus/Grafana)

### Phase 3
- Kubernetes deployment
- Multi-region deployment
- Real-time processing
- GraphQL API

---

**Document Version**: 1.0  
**Last Updated**: 2025-10-10  
**Maintained By**: Development Team